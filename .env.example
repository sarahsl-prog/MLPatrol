# MLPatrol Environment Variables

# ============================================================================
# LLM Configuration
# ============================================================================

# Option 1: Cloud LLMs (requires API key)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Option 2: Local LLMs (no API key required, fully private)
USE_LOCAL_LLM=false  # Set to 'true' to use local LLM instead of cloud

# Local LLM Settings (only used if USE_LOCAL_LLM=true)
# Recommended models:
#   - ollama/llama3.1:8b (fast, general use - 8GB RAM)
#   - ollama/llama3.1:70b (high accuracy - 48GB RAM)
#   - ollama/mistral-small:3.1 (balanced - 16GB RAM)
#   - ollama/qwen2.5:14b (code analysis - 12GB RAM)
LOCAL_LLM_MODEL=ollama/llama3.1:8b
LOCAL_LLM_URL=http://localhost:11434

# Optional: HuggingFace
HUGGINGFACE_API_KEY=your_hf_api_key_here

# Application Settings
LOG_LEVEL=INFO
MAX_AGENT_ITERATIONS=10
